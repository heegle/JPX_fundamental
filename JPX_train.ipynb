{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "committed-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.tseries.offsets as offsets\n",
    "from pandas.tseries.holiday import *\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "import lightgbm as lgb\n",
    "#import optuna.integration.lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# 表示用の設定変更\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "danish-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#祝日カレンダーのクラスJpCalendar定義\n",
    "\n",
    "class JpCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "    Holiday('1231', month=12, day=31),\n",
    "    Holiday('0101', month=1, day=1),\n",
    "    Holiday('0102', month=1, day=2),\n",
    "    Holiday('0103', month=1, day=3),        \n",
    "    Holiday('成人の日', year =2016, month=1, day=11),\n",
    "    Holiday('建国記念の日', year =2016, month=2, day=11),\n",
    "    Holiday('春分の日', year =2016, month=3, day=20),\n",
    "    Holiday('休日', year =2016, month=3, day=21),\n",
    "    Holiday('昭和の日', year =2016, month=4, day=29),\n",
    "    Holiday('憲法記念日', year =2016, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2016, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2016, month=5, day=5),\n",
    "    Holiday('海の日', year =2016, month=7, day=18),\n",
    "    Holiday('山の日', year =2016, month=8, day=11),\n",
    "    Holiday('敬老の日', year =2016, month=9, day=19),\n",
    "    Holiday('秋分の日', year =2016, month=9, day=22),\n",
    "    Holiday('体育の日', year =2016, month=10, day=10),\n",
    "    Holiday('文化の日', year =2016, month=11, day=3),\n",
    "    Holiday('勤労感謝の日', year =2016, month=11, day=23),\n",
    "    Holiday('天皇誕生日', year =2016, month=12, day=23),\n",
    "    Holiday('休日', year =2017, month=1, day=2),\n",
    "    Holiday('成人の日', year =2017, month=1, day=9),\n",
    "    Holiday('建国記念の日', year =2017, month=2, day=11),\n",
    "    Holiday('春分の日', year =2017, month=3, day=20),\n",
    "    Holiday('昭和の日', year =2017, month=4, day=29),\n",
    "    Holiday('憲法記念日', year =2017, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2017, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2017, month=5, day=5),\n",
    "    Holiday('海の日', year =2017, month=7, day=17),\n",
    "    Holiday('山の日', year =2017, month=8, day=11),\n",
    "    Holiday('敬老の日', year =2017, month=9, day=18),\n",
    "    Holiday('秋分の日', year =2017, month=9, day=23),\n",
    "    Holiday('体育の日', year =2017, month=10, day=9),\n",
    "    Holiday('文化の日', year =2017, month=11, day=3),\n",
    "    Holiday('勤労感謝の日', year =2017, month=11, day=23),\n",
    "    Holiday('天皇誕生日', year =2017, month=12, day=23),\n",
    "    Holiday('成人の日', year =2018, month=1, day=8),\n",
    "    Holiday('建国記念の日', year =2018, month=2, day=11),\n",
    "    Holiday('休日', year =2018, month=2, day=12),\n",
    "    Holiday('春分の日', year =2018, month=3, day=21),\n",
    "    Holiday('昭和の日', year =2018, month=4, day=29),\n",
    "    Holiday('休日', year =2018, month=4, day=30),\n",
    "    Holiday('憲法記念日', year =2018, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2018, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2018, month=5, day=5),\n",
    "    Holiday('海の日', year =2018, month=7, day=16),\n",
    "    Holiday('山の日', year =2018, month=8, day=11),\n",
    "    Holiday('敬老の日', year =2018, month=9, day=17),\n",
    "    Holiday('秋分の日', year =2018, month=9, day=23),\n",
    "    Holiday('休日', year =2018, month=9, day=24),\n",
    "    Holiday('体育の日', year =2018, month=10, day=8),\n",
    "    Holiday('文化の日', year =2018, month=11, day=3),\n",
    "    Holiday('勤労感謝の日', year =2018, month=11, day=23),\n",
    "    Holiday('天皇誕生日', year =2018, month=12, day=23),\n",
    "    Holiday('休日', year =2018, month=12, day=24),\n",
    "    Holiday('成人の日', year =2019, month=1, day=14),\n",
    "    Holiday('建国記念の日', year =2019, month=2, day=11),\n",
    "    Holiday('春分の日', year =2019, month=3, day=21),\n",
    "    Holiday('昭和の日', year =2019, month=4, day=29),\n",
    "    Holiday('休日', year =2019, month=4, day=30),\n",
    "    Holiday('休日（祝日扱い）', year =2019, month=5, day=1),\n",
    "    Holiday('休日', year =2019, month=5, day=2),\n",
    "    Holiday('憲法記念日', year =2019, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2019, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2019, month=5, day=5),\n",
    "    Holiday('休日', year =2019, month=5, day=6),\n",
    "    Holiday('海の日', year =2019, month=7, day=15),\n",
    "    Holiday('山の日', year =2019, month=8, day=11),\n",
    "    Holiday('休日', year =2019, month=8, day=12),\n",
    "    Holiday('敬老の日', year =2019, month=9, day=16),\n",
    "    Holiday('秋分の日', year =2019, month=9, day=23),\n",
    "    Holiday('体育の日（スポーツの日）', year =2019, month=10, day=14),\n",
    "    Holiday('休日（祝日扱い）', year =2019, month=10, day=22),\n",
    "    Holiday('文化の日', year =2019, month=11, day=3),\n",
    "    Holiday('休日', year =2019, month=11, day=4),\n",
    "    Holiday('勤労感謝の日', year =2019, month=11, day=23),\n",
    "    Holiday('成人の日', year =2020, month=1, day=13),\n",
    "    Holiday('建国記念の日', year =2020, month=2, day=11),\n",
    "    Holiday('天皇誕生日', year =2020, month=2, day=23),\n",
    "    Holiday('休日', year =2020, month=2, day=24),\n",
    "    Holiday('春分の日', year =2020, month=3, day=20),\n",
    "    Holiday('昭和の日', year =2020, month=4, day=29),\n",
    "    Holiday('憲法記念日', year =2020, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2020, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2020, month=5, day=5),\n",
    "    Holiday('休日', year =2020, month=5, day=6),\n",
    "    Holiday('海の日', year =2020, month=7, day=23),\n",
    "    Holiday('スポーツの日', year =2020, month=7, day=24),\n",
    "    Holiday('山の日', year =2020, month=8, day=10),\n",
    "    Holiday('敬老の日', year =2020, month=9, day=21),\n",
    "    Holiday('秋分の日', year =2020, month=9, day=22),\n",
    "    Holiday('文化の日', year =2020, month=11, day=3),\n",
    "    Holiday('勤労感謝の日', year =2020, month=11, day=23),\n",
    "    Holiday('成人の日', year =2021, month=1, day=11),\n",
    "    Holiday('建国記念の日', year =2021, month=2, day=11),\n",
    "    Holiday('天皇誕生日', year =2021, month=2, day=23),\n",
    "    Holiday('春分の日', year =2021, month=3, day=20),\n",
    "    Holiday('昭和の日', year =2021, month=4, day=29),\n",
    "    Holiday('憲法記念日', year =2021, month=5, day=3),\n",
    "    Holiday('みどりの日', year =2021, month=5, day=4),\n",
    "    Holiday('こどもの日', year =2021, month=5, day=5),\n",
    "    Holiday('海の日', year =2021, month=7, day=22),\n",
    "    Holiday('スポーツの日', year =2021, month=7, day=23),\n",
    "    Holiday('山の日', year =2021, month=8, day=8),\n",
    "    Holiday('休日', year =2021, month=8, day=9),\n",
    "    Holiday('敬老の日', year =2021, month=9, day=20),\n",
    "    Holiday('秋分の日', year =2021, month=9, day=23),\n",
    "    Holiday('文化の日', year =2021, month=11, day=3),\n",
    "    Holiday('勤労感謝の日', year =2021, month=11, day=23),\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "selective-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変数定義\n",
    "dataset_dir=\"./data\"\n",
    "mil = 1000000\n",
    "\n",
    "#祝日カレンダーのクラス生成\n",
    "tse = JpCalendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "constant-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "#スピアマン順位相関係数の計算関数3つ（numrank, spearman, eval_spearman)定義\n",
    "\n",
    "def numrank(a):\n",
    "    u, inv, counts = np.unique(a, return_inverse=True, return_counts=True)\n",
    "    uniqueRankNd = np.array(np.hstack((0, counts[:-1].cumsum())), dtype='float32')\n",
    "    uniqueRankNd = (counts == 1) * uniqueRankNd + (counts != 1) * (2 * uniqueRankNd + counts - 1) / counts\n",
    "    priceRankNd = np.ones_like(inv) * inv.shape[0] - uniqueRankNd[inv]\n",
    "\n",
    "    return priceRankNd\n",
    "\n",
    "def spearman(y_true, y_pred):\n",
    "\n",
    "    y1 = numrank(y_true)\n",
    "    y2 = numrank(y_pred)\n",
    "    correlation, pvalue = spearmanr(y1, y2)\n",
    "    return correlation\n",
    "\n",
    "\n",
    "def eval_spearman(preds, data):\n",
    "\n",
    "    y_true = data.get_label()\n",
    "    return 'sp', spearman(y_true, preds), True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-williams",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "advised-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習対象期間と評価対象期間の設定\n",
    "dates_tr = \"2017-01-01\"\n",
    "datee_tr = \"2019-12-31\"\n",
    "dates_vl = \"2020-01-01\"\n",
    "datee_vl = \"2020-11-30\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "direct-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#各種ファイルのインポート\n",
    "m_conf = pd.read_csv(f\"{dataset_dir}/m_forecast_confidence.csv\")\n",
    "m_qs = pd.read_csv(f\"{dataset_dir}/m_qsales.csv\")\n",
    "m_soyaku = pd.read_csv(f\"{dataset_dir}/m_soyaku.csv\")\n",
    "m_yutai = pd.read_csv(f\"{dataset_dir}/m_yutai.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "existing-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_bk = pd.read_csv(f\"{dataset_dir}/stock_list.csv.gz\")\n",
    "sp_bk = pd.read_csv(f\"{dataset_dir}/stock_price.csv.gz\")\n",
    "sf_bk = pd.read_csv(f\"{dataset_dir}/stock_fin.csv.gz\")\n",
    "slb_bk = pd.read_csv(f\"{dataset_dir}/stock_labels.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "analyzed-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = sl_bk.copy()\n",
    "sp = sp_bk.copy()\n",
    "sf = sf_bk.copy()\n",
    "slb = slb_bk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "egyptian-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#項目名のリネーム\n",
    "sl = sl.rename(columns={\n",
    "                        \"prediction_target\": \"target\", \n",
    "                        \"Local Code\": \"code\",\n",
    "                        \"Name (English)\": \"name\",\n",
    "                        \"Section/Products\": \"section\",\n",
    "                        \"Size Code (New Index Series)\": \"sizecode\",\n",
    "                        \"17 Sector(Code)\": \"17sec\",\n",
    "                        \"33 Sector(Code)\": \"33sec\",\n",
    "                        \"IssuedShareEquityQuote IssuedShare\": \"issued\",\n",
    "                       })\n",
    "\n",
    "sp = sp.rename(columns={\n",
    "                        \"Local Code\": \"code\",\n",
    "                        \"EndOfDayQuote Date\": \"date\",\n",
    "                        \"EndOfDayQuote Open\" : \"open\",\n",
    "                        \"EndOfDayQuote High\" : \"high\",\n",
    "                        \"EndOfDayQuote Low\" : \"low\",\n",
    "                        \"EndOfDayQuote Close\" : \"close\",\n",
    "                        \"EndOfDayQuote ExchangeOfficialClose\": \"eclose\",\n",
    "                        \"EndOfDayQuote Volume\": \"vol\",\n",
    "                        \"EndOfDayQuote CumulativeAdjustmentFactor\": \"adfac\",\n",
    "                       })\n",
    "\n",
    "sf = sf.rename(columns={\n",
    "                        \"base_date\": \"date\",\n",
    "                        \"Local Code\": \"code\",\n",
    "                        \"Result_FinancialStatement AccountingStandard\": \"accstd\",\n",
    "                        \"Result_FinancialStatement FiscalPeriodEnd\": \"period\",\n",
    "                        \"Result_FinancialStatement ReportType\": \"rtype\",\n",
    "                        \"Result_FinancialStatement FiscalYear\": \"fyear\",\n",
    "                        \"Result_FinancialStatement ModifyDate\": \"moddate\",\n",
    "                        \"Result_FinancialStatement CompanyType\": \"ctype\",\n",
    "                        \"Result_FinancialStatement ChangeOfFiscalYearEnd\": \"FYch\",\n",
    "                        \"Result_FinancialStatement NetSales\": \"sales\",\n",
    "                        \"Result_FinancialStatement OperatingIncome\": \"opein\",\n",
    "                        \"Result_FinancialStatement OrdinaryIncome\": \"ordin\",\n",
    "                        \"Result_FinancialStatement NetIncome\": \"netin\",\n",
    "                        \"Result_FinancialStatement TotalAssets\": \"tasset\",\n",
    "                        \"Result_FinancialStatement NetAssets\": \"nasset\",\n",
    "                        \"Result_FinancialStatement CashFlowsFromOperatingActivities\": \"opecf\",\n",
    "                        \"Result_FinancialStatement CashFlowsFromFinancingActivities\": \"fincf\",\n",
    "                        \"Result_FinancialStatement CashFlowsFromInvestingActivities\": \"invcf\",\n",
    "                        \"Forecast_FinancialStatement AccountingStandard\": \"accstd_f\",\n",
    "                        \"Forecast_FinancialStatement FiscalPeriodEnd\": \"period_f\",\n",
    "                        \"Forecast_FinancialStatement ReportType\": \"rtype_f\",\n",
    "                        \"Forecast_FinancialStatement FiscalYear\": \"fyear_f\",\n",
    "                        \"Forecast_FinancialStatement ModifyDate\": \"moddate_f\",\n",
    "                        \"Forecast_FinancialStatement CompanyType\": \"ctype_f\",\n",
    "                        \"Forecast_FinancialStatement ChangeOfFiscalYearEnd\": \"FYch_f\",\n",
    "                        \"Forecast_FinancialStatement NetSales\": \"sales_f\",\n",
    "                        \"Forecast_FinancialStatement OperatingIncome\": \"opein_f\",\n",
    "                        \"Forecast_FinancialStatement OrdinaryIncome\": \"ordin_f\",\n",
    "                        \"Forecast_FinancialStatement NetIncome\": \"netin_f\",\n",
    "                        \"Result_Dividend FiscalPeriodEnd\": \"divperiod\",\n",
    "                        \"Result_Dividend ReportType\": \"div_rtype\",\n",
    "                        \"Result_Dividend ModifyDate\": \"divmoddate\",\n",
    "                        \"Result_Dividend RecordDate\": \"divdt\",\n",
    "                        \"Result_Dividend QuarterlyDividendPerShare\": \"qdiv\",\n",
    "                        \"Result_Dividend AnnualDividendPerShare\": \"adiv\",\n",
    "                        \"Forecast_Dividend FiscalPeriodEnd\": \"divperiod_f\",\n",
    "                        \"Forecast_Dividend ReportType\": \"div_rtype_f\",\n",
    "                        \"Forecast_Dividend ModifyDate\": \"divmoddate_f\",\n",
    "                        \"Forecast_Dividend RecordDate\": \"divdt_f\",\n",
    "                        \"Forecast_Dividend QuarterlyDividendPerShare\": \"qdiv_f\",\n",
    "                        \"Forecast_Dividend AnnualDividendPerShare\": \"adiv_f\",\n",
    "                       })\n",
    "\n",
    "#日付型に変換\n",
    "sp.loc[:, \"date\"] = pd.to_datetime(sp.loc[:, \"date\"])\n",
    "sf.loc[:, \"date\"] = pd.to_datetime(sf.loc[:, \"date\"])\n",
    "sf.loc[:, \"divdt\"] = pd.to_datetime(sf.loc[:, \"divdt\"])\n",
    "sf.loc[:, \"divdt_f\"] = pd.to_datetime(sf.loc[:, \"divdt_f\"])\n",
    "\n",
    "#東証システム障害の日除外\n",
    "sp = sp[sp[\"date\"]!=\"2020-10-01\"]\n",
    "\n",
    "sl = pd.merge(sl,m_soyaku, on=[\"code\"], how=\"left\")\n",
    "sl.loc[sl[\"soyaku\"].isnull(), \"soyaku\"] = 0\n",
    "\n",
    "sf.loc[sf[\"divdt_f\"].isnull(), \"divdt_f\"] = pd.to_datetime(sf[\"divperiod_f\"].str[:4] + \"-\" + sf[\"divperiod_f\"].str[5:7] + \"-\" + \"01\") + offsets.MonthEnd()\n",
    "\n",
    "sf = sf.sort_values(['code', 'date'])\n",
    "sp = sp.sort_values(['code', 'date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "approximate-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#項目名のリネーム\n",
    "slb = slb.rename(columns={\n",
    "                        \"base_date\": \"date\",\n",
    "                        \"Local Code\": \"code\",\n",
    "                       })\n",
    "#日付型に変換\n",
    "slb.loc[:, \"date\"] = pd.to_datetime(slb.loc[:, \"date\"])\n",
    "slb.loc[:, \"label_date_20\"] = pd.to_datetime(slb.loc[:, \"label_date_20\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "systematic-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictでは不要\n",
    "#20日以内修正開示があった場合に、オリジナルを除外\n",
    "sf = sf[~((sf[\"code\"]==sf.shift(-1)[\"code\"]) & (sf[\"date\"] + dt.timedelta(days = 20) >= sf.shift(-1)[\"date\"]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "three-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hideo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\hideo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#決算数値を年間数値に換算\n",
    "\n",
    "sf = pd.merge(sf,m_qs, on=[\"code\"], how=\"left\")\n",
    "\n",
    "sfan = sf[[\"code\",\"period\",\"rtype\"]].drop_duplicates()\n",
    "sfan = sfan[sfan[\"rtype\"]==\"Annual\"]\n",
    "\n",
    "sfan[\"period\"] = np.where(sfan[\"period\"].isnull(), \"0000/00\", sfan[\"period\"])\n",
    "sfan[\"mondiff\"] = np.nan\n",
    "sfan[\"mondiff\"][1:] = np.where((sfan[\"period\"][1:].isnull()) | (sfan.shift(1)[\"period\"][1:].isnull()) | (sfan[\"code\"][1:]!=sfan.shift(1)[\"code\"][1:]), np.nan, \n",
    "                         sfan[\"period\"][1:].str[:4].astype(int)*12 + sfan[\"period\"][1:].str[5:7].astype(int)\n",
    "                         - (sfan.shift(1)[\"period\"][1:].str[:4].astype(int)*12 + sfan.shift(1)[\"period\"][1:].str[5:7].astype(int)))\n",
    "sf[\"period\"] = np.where(sf[\"period\"]==\"0000/00\", np.nan, sf[\"period\"])\n",
    "sf = pd.merge(sf,sfan, on=[\"code\",\"period\",\"rtype\"], how=\"left\")\n",
    "\n",
    "sf[\"qsfac\"] = np.where(sf[\"FYch\"] == 1, sf[\"mondiff\"] / 12, 1)\n",
    "sf[\"qsfac\"] = np.where(sf[\"rtype\"]==\"Q1\", sf[\"qs1\"], sf[\"qsfac\"])\n",
    "sf[\"qsfac\"] = np.where(sf[\"rtype\"]==\"Q2\", sf[\"qs2\"], sf[\"qsfac\"])\n",
    "sf[\"qsfac\"] = np.where(sf[\"rtype\"]==\"Q3\", sf[\"qs3\"], sf[\"qsfac\"])\n",
    "\n",
    "sfan = sf[[\"code\",\"period_f\",\"rtype_f\"]].drop_duplicates()\n",
    "sfan = sfan[sfan[\"rtype_f\"]==\"Annual\"]\n",
    "\n",
    "sfan[\"period_f\"] = np.where(sfan[\"period_f\"].isnull(), \"0000/00\", sfan[\"period_f\"])\n",
    "sfan[\"mondiff_f\"] = np.nan\n",
    "sfan[\"mondiff_f\"][1:] = np.where((sfan[\"period_f\"][1:].isnull()) | (sfan.shift(1)[\"period_f\"][1:].isnull()) | (sfan[\"code\"][1:]!=sfan.shift(1)[\"code\"][1:]), np.nan, \n",
    "                         sfan[\"period_f\"][1:].str[:4].astype(int)*12 + sfan[\"period_f\"][1:].str[5:7].astype(int)\n",
    "                         - (sfan.shift(1)[\"period_f\"][1:].str[:4].astype(int)*12 + sfan.shift(1)[\"period_f\"][1:].str[5:7].astype(int)))\n",
    "sf[\"period_f\"] = np.where(sf[\"period_f\"]==\"0000/00\", np.nan, sf[\"period_f\"])\n",
    "sf = pd.merge(sf,sfan, on=[\"code\",\"period_f\",\"rtype_f\"], how=\"left\")\n",
    "\n",
    "\n",
    "sf[\"qsfac_f\"] = np.where(sf[\"FYch_f\"] == 1, sf[\"mondiff_f\"] / 12, 1)\n",
    "sf[\"qsfac_f\"] = np.where(sf[\"rtype_f\"]==\"Q1\", sf[\"qs1\"], sf[\"qsfac_f\"])\n",
    "sf[\"qsfac_f\"] = np.where(sf[\"rtype_f\"]==\"Q2\", sf[\"qs2\"], sf[\"qsfac_f\"])\n",
    "sf[\"qsfac_f\"] = np.where(sf[\"rtype_f\"]==\"Q3\", sf[\"qs3\"], sf[\"qsfac_f\"])\n",
    "\n",
    "\n",
    "sf[\"noresult\"] = np.where(sf[\"sales\"].isnull() & sf[\"opein\"].isnull() & sf[\"ordin\"].isnull() & sf[\"netin\"].isnull(), 1, 0)\n",
    "sf[\"nofrct\"] = np.where(sf[\"sales_f\"].isnull() & sf[\"opein_f\"].isnull() & sf[\"ordin_f\"].isnull() & sf[\"netin_f\"].isnull(), 1, 0)\n",
    "\n",
    "sf[\"nofrct\"] = np.where((sf[\"code\"] == sf.shift(1)[\"code\"]) \n",
    "         & (sf[\"accstd_f\"] == sf.shift(1)[\"accstd_f\"]) & (sf[\"period_f\"] == sf.shift(1)[\"period_f\"])\n",
    "         & (sf[\"sales_f\"] == sf.shift(1)[\"sales_f\"]) & (sf[\"opein_f\"] == sf.shift(1)[\"opein_f\"])\n",
    "         & (sf[\"ordin_f\"] == sf.shift(1)[\"ordin_f\"]) & (sf[\"netin_f\"] == sf.shift(1)[\"netin_f\"]), \n",
    "                        1, sf[\"nofrct\"])\n",
    "\n",
    "sf[\"sales_aad\"] = sf[\"sales\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"sales_aad_f\"] = sf[\"sales_f\"] * 1 / sf[\"qsfac_f\"]\n",
    "sf[\"opein_aad\"] = sf[\"opein\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"opein_aad_f\"] = sf[\"opein_f\"] * 1 / sf[\"qsfac_f\"]\n",
    "sf[\"ordin_aad\"] = sf[\"ordin\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"ordin_aad_f\"] = sf[\"ordin_f\"] * 1 / sf[\"qsfac_f\"]\n",
    "sf[\"netin_aad\"] = sf[\"netin\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"netin_aad_f\"] = sf[\"netin_f\"] * 1 / sf[\"qsfac_f\"]\n",
    "\n",
    "sf[\"sales_aad_t\"] = np.where(sf[\"sales_aad_f\"].isnull()==False, sf[\"sales_aad_f\"], np.where(sf[\"nofrct\"]==0, np.nan, sf[\"sales_aad\"]))\n",
    "sf[\"opein_aad_t\"] = np.where(sf[\"opein_aad_f\"].isnull()==False, sf[\"opein_aad_f\"], np.where(sf[\"nofrct\"]==0, np.nan, sf[\"opein_aad\"]))\n",
    "sf[\"ordin_aad_t\"] = np.where(sf[\"ordin_aad_f\"].isnull()==False, sf[\"ordin_aad_f\"], np.where(sf[\"nofrct\"]==0, np.nan, sf[\"ordin_aad\"]))\n",
    "sf[\"netin_aad_t\"] = np.where(sf[\"netin_aad_f\"].isnull()==False, sf[\"netin_aad_f\"], np.where(sf[\"nofrct\"]==0, np.nan, sf[\"netin_aad\"]))\n",
    "\n",
    "sf[\"accstd_t\"] = np.where(sf[\"nofrct\"]==0, sf[\"accstd_f\"], sf[\"accstd\"])\n",
    "sf[\"fyear_t\"] = np.where(sf[\"nofrct\"]==0, sf[\"fyear_f\"], sf[\"fyear\"])\n",
    "\n",
    "sf[\"opecf_aad\"] = sf[\"opecf\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"fincf_aad\"] = sf[\"fincf\"] * 1 / sf[\"qsfac\"]\n",
    "sf[\"invcf_aad\"] = sf[\"invcf\"] * 1 / sf[\"qsfac\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "authorized-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#四半期配当をみなし年換算する関数div_aad定義\n",
    "def div_aad(rtype, fig):\n",
    "    return np.where(rtype == \"Q2\", fig * 1.5, np.where((rtype == \"Q1\") | (rtype == \"Q3\"), fig*2.5, fig))\n",
    "\n",
    "#四半期配当を年間配当にみなし換算\n",
    "sf_divdt = sf[[\"code\", \"divdt\"]].drop_duplicates().copy()\n",
    "sf_divdt_f = sf[[\"code\", \"divdt_f\"]].drop_duplicates().copy()\n",
    "sf_divdt_f = sf_divdt_f.rename(columns={\"divdt_f\": \"divdt\"})\n",
    "sf_divdt = pd.concat([sf_divdt, sf_divdt_f]).drop_duplicates()\n",
    "sf_divdt = sf_divdt[sf_divdt[\"divdt\"].isnull()==False]\n",
    "\n",
    "sp_adfac = sp[[\"code\", \"date\",\"adfac\"]].drop_duplicates().copy()\n",
    "sp_adfac[\"adfac\"] = sp.groupby(\"code\").shift(3)[\"adfac\"]\n",
    "sp_adfac = sp_adfac.rename(columns={\"date\": \"divdt\", \"adfac\": \"adfac_divdt\"})\n",
    "\n",
    "sp_adfac = pd.concat([sp_adfac, sf_divdt])\n",
    "\n",
    "sp_adfac = sp_adfac.sort_values(['code', 'divdt'])\n",
    "sp_adfac[\"adfac_divdt\"] = sp_adfac[\"adfac_divdt\"].fillna(method='ffill')\n",
    "\n",
    "sp_adfac = sp_adfac.drop_duplicates()\n",
    "sf = pd.merge(sf, sp_adfac, on=['code', 'divdt'], how=\"left\")\n",
    "\n",
    "sp_adfac = sp_adfac.rename(columns={\"divdt\": \"divdt_f\", \"adfac_divdt\": \"adfac_divdt_f\"})\n",
    "sf = pd.merge(sf, sp_adfac, on=['code', 'divdt_f'], how=\"left\")\n",
    "\n",
    "sf[\"qdiv\"] = sf[\"qdiv\"] / sf[\"adfac_divdt\"]\n",
    "sf[\"adiv\"] = sf[\"adiv\"] / sf[\"adfac_divdt\"]\n",
    "\n",
    "sf[\"qdiv_f\"] = sf[\"qdiv_f\"] / sf[\"adfac_divdt_f\"]\n",
    "sf[\"adiv_f\"] = sf[\"adiv_f\"] / sf[\"adfac_divdt_f\"]\n",
    "\n",
    "sf[\"qdiv_aad\"] =  np.where(sf[\"div_rtype\"] == \"Annual\", sf[\"adiv\"], div_aad(sf[\"rtype\"], sf[\"qdiv\"]))\n",
    "sf[\"qdiv_aad_f\"] =  np.where(sf[\"div_rtype_f\"] == \"Annual\", sf[\"adiv_f\"], div_aad(sf[\"rtype_f\"], sf[\"qdiv_f\"]))\n",
    "sf[\"qdiv_aad_t\"] = np.where(sf[\"qdiv_aad_f\"].isnull(), sf[\"qdiv_aad\"], sf[\"qdiv_aad_f\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "tender-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hideo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:704: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  PerformanceWarning,\n"
     ]
    }
   ],
   "source": [
    "#銘柄の権利落ち日を特定\n",
    "sf[\"divkenridt\"] = np.where(sf[\"divdt\"] >= \"2019-07-18\", sf[\"divdt\"] + offsets.CustomBusinessDay(-2, calendar=tse),sf[\"divdt\"] + offsets.CustomBusinessDay(-3, calendar=tse))\n",
    "sf[\"divkenridt_f\"] = np.where(sf[\"divdt_f\"] >= \"2019-07-18\", sf[\"divdt_f\"] + offsets.CustomBusinessDay(-2, calendar=tse),sf[\"divdt_f\"] + offsets.CustomBusinessDay(-3, calendar=tse))\n",
    "\n",
    "sf[\"kenri_f\"] = np.where(\n",
    "             (sf[\"divkenridt_f\"] <= sf[\"date\"] + offsets.CustomBusinessDay(30, calendar=tse))\n",
    "                &(sf[\"divkenridt_f\"] > sf[\"date\"] + offsets.CustomBusinessDay(0, calendar=tse)), 1, 0)\n",
    "\n",
    "sf[\"kenriochi_f\"] = np.where(\n",
    "             (sf[\"divkenridt_f\"] + offsets.CustomBusinessDay(1, calendar=tse) <= sf[\"date\"] + offsets.CustomBusinessDay(20, calendar=tse))\n",
    "                & (sf[\"divkenridt_f\"] + offsets.CustomBusinessDay(1, calendar=tse) > sf[\"date\"] ), 1, 0)\n",
    "\n",
    "sf[\"post_kenriochi_f\"] = np.where(\n",
    "            ( (sf[\"divkenridt_f\"] + offsets.CustomBusinessDay(1, calendar=tse) <= sf[\"date\"])\n",
    "                & (sf[\"divkenridt_f\"] + offsets.CustomBusinessDay(20, calendar=tse) > sf[\"date\"]))\n",
    "            | ((sf[\"divkenridt\"] + offsets.CustomBusinessDay(1, calendar=tse) <= sf[\"date\"])\n",
    "                & (sf[\"divkenridt\"] + offsets.CustomBusinessDay(20, calendar=tse) > sf[\"date\"])), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "superb-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x営業日日前からの株価変化率を算出\n",
    "sp = sp.sort_values(['code', 'date'])\n",
    "\n",
    "sp[\"eclose\"] = sp[\"eclose\"].replace(0, np.nan).interpolate()\n",
    "\n",
    "sp[\"eclose_ch_1\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(1)\n",
    "sp[\"eclose_ch_3\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(3)\n",
    "sp[\"eclose_ch_5\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(5)\n",
    "sp[\"eclose_ch_10\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(10)\n",
    "sp[\"eclose_ch_20\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(20)\n",
    "sp[\"eclose_ch_40\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(40)\n",
    "sp[\"eclose_ch_60\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(60)\n",
    "sp[\"eclose_ch_120\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(120)\n",
    "\n",
    "sp[\"eclose_ch_mid\"] = sp.groupby(\"code\")[\"eclose\"].pct_change(240)\n",
    "\n",
    "#120営業日前からの出来高変化率の対数を算出\n",
    "sp[\"vol_ch\"] = np.log(1.01 + np.where((sp.groupby(\"code\").shift(120)[\"vol\"]==0) | (sp.groupby(\"code\").shift(120)[\"vol\"].isnull()), sp[\"vol\"]/100, sp.groupby(\"code\")[\"vol\"].pct_change(120)))\n",
    "\n",
    "#終値がnull値のレコードを除外\n",
    "sp = sp[sp[\"eclose\"].isnull()==False]\n",
    "\n",
    "#日ごと銘柄ごとのボラティリティを算出\n",
    "sp[\"vola\"] = (sp[\"high\"] - sp[\"low\"])/ sp[\"eclose\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "actual-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習期間における銘柄ごとのボラティリティを算出\n",
    "sp_code_max = sp[(sp[\"date\"]>=dates_tr)&(sp[\"date\"]<=datee_tr)][[\"code\",\"eclose\"]].groupby(\"code\").max().reset_index()\n",
    "sp_code_min = sp[(sp[\"date\"]>=dates_tr)&(sp[\"date\"]<=datee_tr)][[\"code\",\"eclose\"]].groupby(\"code\").min().reset_index()\n",
    "sp_code_median = sp[(sp[\"date\"]>=dates_tr)&(sp[\"date\"]<=datee_tr)][[\"code\",\"eclose\"]].groupby(\"code\").median().reset_index()\n",
    "sp_code_max = sp_code_max.rename(columns={\"eclose\": \"eclose_max\"})\n",
    "sp_code_min = sp_code_min.rename(columns={\"eclose\": \"eclose_min\"})\n",
    "sp_code_median = sp_code_median.rename(columns={\"eclose\": \"eclose_median\"})\n",
    "sp_code = pd.merge(sp_code_max, sp_code_min, on=[\"code\"], how=\"left\")\n",
    "sp_code = pd.merge(sp_code, sp_code_median, on=[\"code\"], how=\"left\")\n",
    "sp_code[\"vola_code\"] = (sp_code[\"eclose_max\"] - sp_code[\"eclose_min\"])/sp_code[\"eclose_median\"] \n",
    "sp = pd.merge(sp, sp_code, on=[\"code\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "pleasant-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "#相場平均の株価変化率を算出\n",
    "sp_macro = sp[[\"date\",\"eclose_ch_1\",\"eclose_ch_3\",\"eclose_ch_10\"]].groupby(\"date\").mean()\n",
    "sp_macro = sp_macro.rename(columns={\"eclose_ch_1\": \"eclose_ch_1_macro\", \"eclose_ch_3\": \"eclose_ch_3_macro\", \"eclose_ch_10\": \"eclose_ch_10_macro\"})\n",
    "sp = pd.merge(sp, sp_macro, on=[\"date\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "sharing-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "#激しい下落があった個別銘柄・日付の判定\n",
    "sp[\"sellmax_code\"] = 0\n",
    "sp.loc[(sp[\"eclose_ch_10\"]>-0.03)&(sp[\"eclose_ch_1\"]<-0.03)&(sp.groupby(\"code\").shift(1)[\"eclose_ch_1\"]<-0.03),\"sellmax_code\"] = 1\n",
    "#激しい相場下落があった日付の判定\n",
    "sp[\"sellmax_macro\"] = 0\n",
    "sp.loc[(sp[\"eclose_ch_10_macro\"]>-0.08)&(sp[\"eclose_ch_1_macro\"]<-0.025)&(sp[\"eclose_ch_3_macro\"]<-0.03),\"sellmax_macro\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "graphic-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ストップ高・安の判定\n",
    "sp[\"eclose_ori\"] = sp[\"eclose\"] * sp[\"adfac\"]\n",
    "\n",
    "sp[\"eclose_tbc_pre_1\"] = sp.groupby(\"code\").shift(1)[\"eclose_ori\"]/sp.groupby(\"code\").shift(1)[\"adfac\"]*sp[\"adfac\"]\n",
    "sp[\"eclose_diff_1\"] = np.round(sp[\"eclose_ori\"] - sp[\"eclose_tbc_pre_1\"])\n",
    "\n",
    "#値幅制限が変更になる場合があるので、>=のほうがよい\n",
    "sp[\"stop\"] = 0\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<100)&(sp[\"eclose_diff_1\"]>=30), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<200)&(sp[\"eclose_diff_1\"]>=50), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<500)&(sp[\"eclose_diff_1\"]>=80), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<700)&(sp[\"eclose_diff_1\"]>=100), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<1000)&(sp[\"eclose_diff_1\"]>=150), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<1500)&(sp[\"eclose_diff_1\"]>=300), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<2000)&(sp[\"eclose_diff_1\"]>=400), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<3000)&(sp[\"eclose_diff_1\"]>=500), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<5000)&(sp[\"eclose_diff_1\"]>=700), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<7000)&(sp[\"eclose_diff_1\"]>=1000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<10000)&(sp[\"eclose_diff_1\"]>=1500), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<15000)&(sp[\"eclose_diff_1\"]>=3000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<20000)&(sp[\"eclose_diff_1\"]>=4000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<30000)&(sp[\"eclose_diff_1\"]>=5000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<50000)&(sp[\"eclose_diff_1\"]>=7000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<70000)&(sp[\"eclose_diff_1\"]>=10000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<100000)&(sp[\"eclose_diff_1\"]>=15000), \"stop\"] = 1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<100)&(sp[\"eclose_diff_1\"]<=-30), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<200)&(sp[\"eclose_diff_1\"]<=-50), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<500)&(sp[\"eclose_diff_1\"]<=-80), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<700)&(sp[\"eclose_diff_1\"]<=-100), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<1000)&(sp[\"eclose_diff_1\"]<=-150), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<1500)&(sp[\"eclose_diff_1\"]<=-300), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<2000)&(sp[\"eclose_diff_1\"]<=-400), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<3000)&(sp[\"eclose_diff_1\"]<=-500), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<5000)&(sp[\"eclose_diff_1\"]<=-700), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<7000)&(sp[\"eclose_diff_1\"]<=-1000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<10000)&(sp[\"eclose_diff_1\"]<=-1500), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<15000)&(sp[\"eclose_diff_1\"]<=-3000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<20000)&(sp[\"eclose_diff_1\"]<=-4000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<30000)&(sp[\"eclose_diff_1\"]<=-5000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<50000)&(sp[\"eclose_diff_1\"]<=-7000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<70000)&(sp[\"eclose_diff_1\"]<=-10000), \"stop\"] = -1\n",
    "sp.loc[(sp[\"eclose_tbc_pre_1\"]<100000)&(sp[\"eclose_diff_1\"]<=-15000), \"stop\"] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "compact-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#窓開きのチャート判定\n",
    "sp[\"window\"] = np.where((sp.groupby(\"code\").shift(1)[\"high\"]*1.06<sp[\"low\"])|(sp.groupby(\"code\").shift(1)[\"low\"]>sp[\"high\"]*1.06), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "intense-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x日移動平均線との乖離率の算出\n",
    "sp[\"eclose_mean5\"] = sp.groupby(\"code\")[\"eclose\"].rolling(5,min_periods=1).mean().reset_index()[\"eclose\"]\n",
    "sp[\"eclose_ch_mean5\"] = (sp[\"eclose\"] - sp[\"eclose_mean5\"]) / sp[\"eclose_mean5\"]\n",
    "sp[\"eclose_mean10\"] = sp.groupby(\"code\")[\"eclose\"].rolling(10,min_periods=1).mean().reset_index()[\"eclose\"]\n",
    "sp[\"eclose_ch_mean10\"] = (sp[\"eclose\"] - sp[\"eclose_mean10\"]) / sp[\"eclose_mean10\"]\n",
    "sp[\"eclose_mean20\"] = sp.groupby(\"code\")[\"eclose\"].rolling(20,min_periods=1).mean().reset_index()[\"eclose\"]\n",
    "sp[\"eclose_ch_mean20\"] = (sp[\"eclose\"] - sp[\"eclose_mean20\"]) / sp[\"eclose_mean20\"]\n",
    "sp[\"eclose_mean40\"] = sp.groupby(\"code\")[\"eclose\"].rolling(40,min_periods=1).mean().reset_index()[\"eclose\"]\n",
    "sp[\"eclose_ch_mean40\"] = (sp[\"eclose\"] - sp[\"eclose_mean40\"]) / sp[\"eclose_mean40\"]\n",
    "sp[\"eclose_mean120\"] = sp.groupby(\"code\")[\"eclose\"].rolling(120,min_periods=1).mean().reset_index()[\"eclose\"]\n",
    "sp[\"eclose_ch_mean120\"] = (sp[\"eclose\"] - sp[\"eclose_mean120\"]) / sp[\"eclose_mean120\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "phantom-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pd.merge(sl, sf, on=[\"code\"], how=\"inner\")\n",
    "sa = pd.merge(sa, sp, on=[\"date\", \"code\"], how=\"left\")\n",
    "sa = sa.sort_values(['code', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "egyptian-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pd.merge(sa, slb, on=[\"date\", \"code\"], how=\"inner\") #predict不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "indian-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_bk = sa.copy() #predict不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "secure-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = sa_bk.copy() #predict不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "digital-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pd.merge(sa, m_conf, on=[\"code\"], how=\"left\")\n",
    "sa.loc[sa[\"fore_conf\"].isnull(), \"fore_conf\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "subjective-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#会計年度変更の判定\n",
    "sa[\"FYshift\"] = np.where((sa[\"fyear_t\"] != sa.groupby(\"code\").shift(1)[\"fyear_t\"]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "humanitarian-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#時価総額の対数の算出\n",
    "sa[\"jikaso\"] = (sa[\"issued\"] * sa[\"eclose\"])/mil\n",
    "sa[\"jikaso_log\"] = np.log((sa[\"issued\"] * sa[\"eclose\"]+1)/mil)\n",
    "\n",
    "#時価総額の対数を分母とした業績変化率の算出\n",
    "sa[\"salesr_aad_t_ch\"] = np.where((sa[\"code\"] == sa.shift(1)[\"code\"]) & (sa[\"accstd_t\"] == sa.shift(1)[\"accstd_t\"]) & (sa[\"fyear_t\"] <= sa.shift(1)[\"fyear_t\"] + 1), sa.groupby([\"code\", \"accstd_t\"])[\"sales_aad_t\"].diff(1) / sa[\"jikaso_log\"], np.nan)\n",
    "sa[\"opeinr_aad_t_ch\"] = np.where((sa[\"code\"] == sa.shift(1)[\"code\"]) & (sa[\"accstd_t\"] == sa.shift(1)[\"accstd_t\"]) & (sa[\"fyear_t\"] <= sa.shift(1)[\"fyear_t\"] + 1), sa.groupby([\"code\", \"accstd_t\"])[\"opein_aad_t\"].diff(1) / sa[\"jikaso_log\"], np.nan)\n",
    "sa[\"ordinr_aad_t_ch\"] = np.where((sa[\"code\"] == sa.shift(1)[\"code\"]) & (sa[\"accstd_t\"] == sa.shift(1)[\"accstd_t\"]) & (sa[\"fyear_t\"] <= sa.shift(1)[\"fyear_t\"] + 1), sa.groupby([\"code\", \"accstd_t\"])[\"ordin_aad_t\"].diff(1) / sa[\"jikaso_log\"], np.nan)\n",
    "sa[\"netinr_aad_t_ch\"] = np.where((sa[\"code\"] == sa.shift(1)[\"code\"]) & (sa[\"accstd_t\"] == sa.shift(1)[\"accstd_t\"]) & (sa[\"fyear_t\"] <= sa.shift(1)[\"fyear_t\"] + 1), sa.groupby([\"code\", \"accstd_t\"])[\"netin_aad_t\"].diff(1) / sa[\"jikaso_log\"], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#配当金額の差分の算出（記念配当のみなし補正含む）\n",
    "sa[\"qdiv_aad_t_ch\"] = np.where(sa[\"qdiv_aad_t\"] / sa[\"eclose\"] > 0.06, sa.groupby(\"code\")[\"qdiv_aad_t\"].diff(1)/3, sa.groupby(\"code\")[\"qdiv_aad_t\"].diff(1))\n",
    "\n",
    "#年利回りの差分の算出\n",
    "sa[\"ayld_t_ch\"] = sa[\"qdiv_aad_t_ch\"] / sa[\"eclose\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dimensional-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#株価売上率の対数の算出\n",
    "sa[\"EPS_sal_f\"] = sa[\"sales_aad_f\"] * mil / sa[\"issued\"]\n",
    "sa[\"PER_sal_f\"] = sa[\"eclose\"] / np.where(sa[\"EPS_sal_f\"]<=0, 1, sa[\"EPS_sal_f\"])\n",
    "sa[\"PER_sal_log_f\"] = np.log(sa[\"PER_sal_f\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "wicked-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33業種ごと240営業日前からの株価変化率の算出\n",
    "eclose_ch_sec = sa.groupby(\"33sec\")[\"eclose_ch_mid\"].mean().reset_index()\n",
    "eclose_ch_sec = eclose_ch_sec.rename(columns={\"eclose_ch_mid\": \"eclose_ch_sec\",})\n",
    "sa = pd.merge(sa, eclose_ch_sec, on=[\"33sec\"], how=\"left\")\n",
    "\n",
    "#各種項目のワンホットベクトル化\n",
    "sa = pd.get_dummies(sa, columns=['section'])\n",
    "sa = pd.get_dummies(sa, columns=['sizecode'])\n",
    "\n",
    "sa[\"ctype_f\"] = np.where(sa[\"ctype_f\"].isnull(), sa[\"ctype\"], sa[\"ctype_f\"])\n",
    "sa = pd.get_dummies(sa, columns=['ctype'])\n",
    "sa = pd.get_dummies(sa, columns=['ctype_f'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "criminal-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_fd = sp.groupby(\"code\")[[\"code\",\"date\"]].head(1).copy()\n",
    "sp_fd = sp_fd.rename(columns={\"date\": \"sp_fdate\"})\n",
    "sa = pd.merge(sa, sp_fd, on=['code'], how=\"left\")\n",
    "\n",
    "#2016年1月4日時点で上場していたか判定\n",
    "sa[\"lc_mature\"] = 0\n",
    "sa[\"lc_mature\"] = np.where(sa[\"sp_fdate\"] <= dt.datetime(2016, 1, 4), 1, 0)\n",
    "\n",
    "#上場後1440営業日過ぎているか判定\n",
    "sa[\"lc_young\"] = 0\n",
    "sa[\"lc_young\"] = np.where((sa[\"lc_mature\"]==0)\n",
    "                   & (sa[\"date\"] - sa[\"sp_fdate\"] <= dt.timedelta(days=1440)), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "pressing-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33業種と権利落ち日周辺かどうかで優待受け取りがあるかどうかのみなし判定\n",
    "sa = pd.merge(sa,m_yutai, on=[\"33sec\"], how=\"left\")\n",
    "sa.loc[(sa[\"yutai\"].isnull()), \"yutai\"] = 0\n",
    "\n",
    "sa.loc[(sa[\"kenri_f\"]==0)&(sa[\"kenriochi_f\"]==0)&(sa[\"post_kenriochi_f\"]==0), \"yutai\"] = 0\n",
    "sa.loc[(sa[\"kenri_f\"]==0)&(sa[\"kenriochi_f\"]==0)&(sa[\"post_kenriochi_f\"]==0), \"yutai\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dedicated-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictでは不要\n",
    "#一部の項目がnull値の場合、予測対象フラグをOFF\n",
    "sa.loc[sa[\"label_high_20\"].isnull(), \"target\"] = 0\n",
    "sa.loc[sa[\"label_low_20\"].isnull(), \"target\"] = 0\n",
    "\n",
    "sa.loc[sa[\"eclose_ch_1\"].isnull(), \"target\"] = 0\n",
    "\n",
    "sa.loc[sa[\"eclose_ch_mid\"].isnull(), \"target\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ranging-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測対象フラグOFFのレコードを予測対象から除外\n",
    "sa = sa[sa[\"target\"]==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dental-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#業績数値変化率の一部がnull値の場合、他の業績数値変化率で置き換え\n",
    "for j in range(2):\n",
    "    for i in range(10):\n",
    "        if len(sa[\"ordinr_aad_t_ch\"].isnull()) > 0:\n",
    "            sa[\"ordinr_aad_t_ch\"] = np.where(sa[\"ordinr_aad_t_ch\"].isnull(), sa[\"opeinr_aad_t_ch\"], sa[\"ordinr_aad_t_ch\"])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for i in range(10):\n",
    "        if len(sa[\"opeinr_aad_t_ch\"].isnull()) > 0:\n",
    "            sa[\"opeinr_aad_t_ch\"] = np.where(sa[\"opeinr_aad_t_ch\"].isnull(),  \n",
    "                                        np.where(sa[\"ordinr_aad_t_ch\"].isnull(), sa[\"salesr_aad_t_ch\"], sa[\"ordinr_aad_t_ch\"]), \n",
    "                                    sa[\"opeinr_aad_t_ch\"])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for i in range(10):\n",
    "        if len(sa[\"salesr_aad_t_ch\"].isnull()) > 0:\n",
    "            sa[\"salesr_aad_t_ch\"] = np.where(sa[\"salesr_aad_t_ch\"].isnull(), \n",
    "                                    np.where(sa[\"opeinr_aad_t_ch\"].isnull(), sa[\"ordinr_aad_t_ch\"], sa[\"opeinr_aad_t_ch\"]), \n",
    "                                    sa[\"salesr_aad_t_ch\"])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "for i in range(10):\n",
    "    if len(sa[\"netinr_aad_t_ch\"].isnull()) > 0:\n",
    "        sa[\"netinr_aad_t_ch\"] =  np.where(sa[\"netinr_aad_t_ch\"].isnull(),\n",
    "                                    np.where(sa[\"ordinr_aad_t_ch\"].isnull(), sa[\"opeinr_aad_t_ch\"], sa[\"ordinr_aad_t_ch\"]), \n",
    "                                          sa[\"netinr_aad_t_ch\"])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#各業績数値が、プラスマイナス転換したか、連続マイナスだったか判定\n",
    "sa[\"opeinr_akakuro\"] = np.where((sa[\"opein_aad_t\"] * sa.groupby(\"code\").shift(1)[\"opein_aad_t\"]<0), 1, 0)\n",
    "sa[\"opeinr_akaaka\"] = np.where((sa[\"opein_aad_t\"] < 0) & (sa.groupby(\"code\").shift(1)[\"opein_aad_t\"] < 0), 1, 0)\n",
    "sa[\"ordinr_akakuro\"] = np.where((sa[\"ordin_aad_t\"] * sa.groupby(\"code\").shift(1)[\"ordin_aad_t\"]<0), 1, 0)\n",
    "sa[\"ordinr_akaaka\"] = np.where((sa[\"ordin_aad_t\"] < 0) & (sa.groupby(\"code\").shift(1)[\"ordin_aad_t\"] < 0), 1, 0)\n",
    "sa[\"netinr_akakuro\"] = np.where((sa[\"netin_aad_t\"] * sa.groupby(\"code\").shift(1)[\"netin_aad_t\"]<0), 1, 0)\n",
    "sa[\"netinr_akaaka\"] = np.where((sa[\"netin_aad_t\"] < 0) & (sa.groupby(\"code\").shift(1)[\"netin_aad_t\"] < 0), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "urban-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#純資産がプラスマイナス転換したか判定\n",
    "sa[\"nasset_akakuro\"] = np.where((sa[\"nasset\"] > 0) & (sa.groupby(\"code\").shift(1)[\"nasset\"] <= 0), 1,  np.where((sa[\"nasset\"] <= 0) & (sa.groupby(\"code\").shift(1)[\"nasset\"] > 0), -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "floppy-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#日付が、全銘柄の売買単位が100株となった2018年10月1日以降かどうか判定\n",
    "sa[\"punit_ch_date\"] = np.where(sa[\"date\"]>=\"2018-10-01\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "rough-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "#売上がマイナスかnull値のレコードを除外\n",
    "sa = sa[(sa[\"sales\"]>0) | (sa[\"sales\"].isnull())] #Predictでは不要。トレーニングでは必要。3件マイナス売上があるので。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "still-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictには不要\n",
    "#20営業日の間の最高値・最安値を記録した日付を判定\n",
    "\n",
    "spl = pd.merge(sp,sl, on=[\"code\"], how=\"inner\")\n",
    "spl[\"jikaso\"] = spl[\"eclose\"] * spl[\"issued\"]\n",
    "\n",
    "sa[\"high_20\"] = np.where(((sa[\"code\"]==6806)&(sa[\"date\"]<=\"2018-01-29\")) | (sa[\"eclose\"]<10000), np.round(sa[\"eclose\"] * (1 + sa[\"label_high_20\"]),1),np.round(sa[\"eclose\"] * (1 + sa[\"label_high_20\"])))\n",
    "sa_p = sa[[\"code\",\"date\",\"high_20\"]].copy()\n",
    "\n",
    "spl[\"date_high_20\"] = spl[\"date\"]\n",
    "spl[\"high_20\"] = spl[\"high\"]\n",
    "\n",
    "sa_p = pd.merge(sa_p, spl[[\"code\", \"date_high_20\",\"high_20\"]], on=[\"code\",\"high_20\"], how=\"left\")\n",
    "sa_p.loc[(sa_p[\"code\"]==6806)&(sa_p[\"date\"]==\"2018-01-30\"), \"date_high_20\"] = pd.to_datetime(\"2018-01-31\")\n",
    "sa_p = sa_p[(sa_p[\"date_high_20\"] <= sa_p[\"date\"] + dt.timedelta(days=40)) & (sa_p[\"date_high_20\"] >= sa_p[\"date\"])]\n",
    "sa_p = sa_p.groupby([\"code\",\"date\"]).head(1).reset_index()\n",
    "\n",
    "sa = pd.merge(sa, sa_p[[\"code\",\"date\", \"date_high_20\"]], on=[\"code\",\"date\"], how=\"left\")\n",
    "\n",
    "\n",
    "sa[\"low_20\"] = np.where(((sa[\"code\"]==6806)&(sa[\"date\"]<=\"2018-01-29\")) | (sa[\"eclose\"]<10000), np.round(sa[\"eclose\"] * (1 + sa[\"label_low_20\"]),1),np.round(sa[\"eclose\"] * (1 + sa[\"label_low_20\"])))\n",
    "\n",
    "sa_p = sa[[\"code\",\"date\",\"low_20\"]].copy()\n",
    "\n",
    "spl[\"date_low_20\"] = spl[\"date\"]\n",
    "spl[\"low_20\"] = spl[\"low\"]\n",
    "\n",
    "sa_p = pd.merge(sa_p, spl[[\"code\", \"date_low_20\",\"low_20\"]], on=[\"code\",\"low_20\"], how=\"left\")\n",
    "sa_p.loc[(sa_p[\"code\"]==6806)&(sa_p[\"date\"]==\"2018-01-30\"), \"date_low_20\"] = pd.to_datetime(\"2018-02-14\")\n",
    "sa_p = sa_p[(sa_p[\"date_low_20\"] <= sa_p[\"date\"] + dt.timedelta(days=40)) & (sa_p[\"date_low_20\"] >= sa_p[\"date\"])]\n",
    "sa_p = sa_p.groupby([\"code\",\"date\"]).head(1).reset_index()\n",
    "\n",
    "sa = pd.merge(sa, sa_p[[\"code\",\"date\", \"date_low_20\"]], on=[\"code\",\"date\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "expected-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict対象外\n",
    "#全銘柄株価の日付ごとの20営業日の間の最高値・最安値を判定\n",
    "sp_macro2 = sp.groupby(\"date\")[[\"eclose\",\"high\",\"low\"]].mean().reset_index()\n",
    "\n",
    "sp_macro2 = sp_macro2.rename(columns={\n",
    "                        \"eclose\": \"eclose_macro\",\n",
    "                        \"high\": \"high_macro\",\n",
    "                        \"low\": \"low_macro\",\n",
    "                       })\n",
    "sp_macro2[\"date_high_20\"] = sp_macro2[\"date\"]\n",
    "sp_macro2[\"date_low_20\"] = sp_macro2[\"date\"]\n",
    "\n",
    "sa = pd.merge(sa,sp_macro2[[\"date\",\"eclose_macro\"]], on=[\"date\"], how=\"left\")\n",
    "sa = pd.merge(sa,sp_macro2[[\"high_macro\",\"date_high_20\"]], on=[\"date_high_20\"], how=\"left\")\n",
    "sa[\"macro_high_ch_20\"] = (sa[\"high_macro\"] - sa[\"eclose_macro\"]) / sa[\"eclose_macro\"]\n",
    "sa = pd.merge(sa,sp_macro2[[\"low_macro\",\"date_low_20\"]], on=[\"date_low_20\"], how=\"left\")\n",
    "sa[\"macro_low_ch_20\"] = (sa[\"low_macro\"] - sa[\"eclose_macro\"]) / sa[\"eclose_macro\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "accredited-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hideo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Predict対象外\n",
    "#33業種ごと全銘柄株価の日付ごとの20営業日の間の最高値・最安値を判定\n",
    "sp_sec2 = spl.groupby([\"date\",\"33sec\"])[\"eclose\",\"high\",\"low\"].mean().reset_index()\n",
    "sp_sec2 = sp_sec2.rename(columns={\n",
    "                        \"eclose\": \"eclose_33sec\",\n",
    "                        \"high\": \"high_33sec\",\n",
    "                        \"low\": \"low_33sec\",\n",
    "                       })\n",
    "sp_sec2[\"date_high_20\"] = sp_sec2[\"date\"]\n",
    "sp_sec2[\"date_low_20\"] = sp_sec2[\"date\"]\n",
    "\n",
    "sa = pd.merge(sa,sp_sec2[[\"date\",\"33sec\",\"eclose_33sec\"]], on=[\"date\",\"33sec\"], how=\"left\")\n",
    "sa = pd.merge(sa,sp_sec2[[\"33sec\",\"date_high_20\",\"high_33sec\"]], on=[\"date_high_20\",\"33sec\"], how=\"left\")\n",
    "sa[\"33sec_high_ch_20\"] = (sa[\"high_33sec\"] - sa[\"eclose_33sec\"]) / sa[\"eclose_33sec\"]\n",
    "sa = pd.merge(sa,sp_sec2[[\"33sec\",\"date_low_20\",\"low_33sec\"]], on=[\"date_low_20\",\"33sec\"], how=\"left\")\n",
    "sa[\"33sec_low_ch_20\"] = (sa[\"low_33sec\"] - sa[\"eclose_33sec\"]) / sa[\"eclose_33sec\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-litigation",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "assumed-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数のリストを作成\n",
    "x_col1_g = [\n",
    "         \"FYshift\", \"ctype_GB\", \"ctype_BK\",\"ctype_SE\",\"ctype_IN\",\"ctype_f_GB\",\"ctype_f_BK\",\"ctype_f_SE\",\"ctype_f_IN\",\n",
    "        \"salesr_aad_t_ch\", \"opeinr_aad_t_ch\", \"ordinr_aad_t_ch\", \"netinr_aad_t_ch\",\n",
    "        \"opeinr_akakuro\", \"opeinr_akaaka\", \"ordinr_akakuro\", \"ordinr_akaaka\", \"netinr_akakuro\", \"netinr_akaaka\",\n",
    "        \"lc_young\",\"lc_mature\",\n",
    "        \"noresult\",\"nofrct\",\"ayld_t_ch\",\n",
    "        \"yutai\",\n",
    "        \"kenri_f\", \"kenriochi_f\",\"post_kenriochi_f\",\n",
    "        \"fore_conf\",\n",
    "        \"eclose\",\n",
    "        \"punit_ch_date\",\n",
    "        \"eclose_ch_mean5\", \"eclose_ch_mean10\",\n",
    "        \"eclose_ch_1\",\"eclose_ch_5\",\"eclose_ch_10\",\"eclose_ch_20\", \"eclose_ch_40\", \"eclose_ch_120\",\n",
    "        \"eclose_ch_sec\", \"vola_code\",\n",
    "        \"soyaku\",\n",
    "        \"PER_sal_log_f\",\n",
    "          \"vola\", \"vol_ch\", \"jikaso_log\",\"stop\",\"window\",\n",
    "         \"section_First Section (Domestic)\", \"section_JASDAQ(Growth/Domestic)\", \"section_JASDAQ(Standard / Domestic)\", \"section_Mothers (Domestic)\",\n",
    "         \"section_Second Section(Domestic)\",\n",
    "        \"sizecode_1\",\"sizecode_2\",\"sizecode_4\",\"sizecode_6\",\"sizecode_7\",\"sizecode_-\",\n",
    "        ]\n",
    "x_col1_h = [\"eclose_ch_60\"]\n",
    "x_col1_l = [\"eclose_ch_mean20\", \"eclose_ch_mean40\", \"eclose_ch_mean120\", \"eclose_ch_mid\",\"sellmax_code\",\"sellmax_macro\",\"nasset_akakuro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "honey-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMのパラメータのリストを作成\n",
    "params={\n",
    "        'learning_rate': 0.005, 'objective': 'mae', \n",
    "        'metric': 'mae', \n",
    "        'boosting_type': 'gbdt', \n",
    "         'num_leaves': 62, 'verbose': -1, 'bagging_fraction': 0.523321698496099, 'feature_fraction': 0.884, \n",
    "         'bagging_freq': 7, 'feature_pre_filter': False, \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "elder-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's l1: 0.085252\tvalid_0's sp: 0.367355\n",
      "[2000]\tvalid_0's l1: 0.0846886\tvalid_0's sp: 0.375214\n",
      "[3000]\tvalid_0's l1: 0.0843893\tvalid_0's sp: 0.378317\n",
      "[4000]\tvalid_0's l1: 0.0843046\tvalid_0's sp: 0.378021\n",
      "[5000]\tvalid_0's l1: 0.0842124\tvalid_0's sp: 0.379255\n",
      "[6000]\tvalid_0's l1: 0.0841859\tvalid_0's sp: 0.378861\n",
      "[500]\tvalid_0's l1: 0.0574764\tvalid_0's sp: 0.349191\n",
      "[1000]\tvalid_0's l1: 0.0574066\tvalid_0's sp: 0.3553\n",
      "[1500]\tvalid_0's l1: 0.0574538\tvalid_0's sp: 0.3559\n"
     ]
    }
   ],
   "source": [
    "#学習・評価対象期間のデータセットを作成\n",
    "df_tr = sa[(sa[\"date\"]>=dates_tr)&(sa[\"date\"]<=datee_tr)]\n",
    "df_vl = sa[(sa[\"date\"]>=dates_vl)&(sa[\"date\"]<=datee_vl)]\n",
    "\n",
    "#高値予測モデルの学習\n",
    "hl = \"high\"\n",
    "a_macro = 0.5\n",
    "a_sec = 0\n",
    "x_col = x_col1_g + x_col1_h\n",
    "num_boost_round = 6000\n",
    "verbose_eval = 1000\n",
    "train_data = lgb.Dataset(df_tr[x_col].values.astype(np.float32), label=(df_tr[f\"label_{hl}_20\"] - a_macro*df_tr[f\"macro_{hl}_ch_20\"] - a_sec*df_tr[f\"33sec_{hl}_ch_20\"]).values.astype(np.float32))\n",
    "eval_data = lgb.Dataset(df_vl[x_col].values.astype(np.float32), label=(df_vl[f\"label_{hl}_20\"] - a_macro*df_vl[f\"macro_{hl}_ch_20\"] - a_sec*df_vl[f\"33sec_{hl}_ch_20\"]).values.astype(np.float32), reference= train_data)\n",
    "\n",
    "model = lgb.train(params,train_data,valid_sets=eval_data, num_boost_round=num_boost_round, verbose_eval=verbose_eval, feval=eval_spearman)\n",
    "\n",
    "#高値予測モデルのエクスポート\n",
    "modelname = f'model_jpx_{hl}.pkl'\n",
    "\n",
    "with open(modelname, 'wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "\n",
    "#安値予測モデルの学習\n",
    "hl = \"low\"\n",
    "a_macro = 1.0\n",
    "a_sec = 0.2        \n",
    "x_col = x_col1_g + x_col1_l\n",
    "num_boost_round = 1500\n",
    "verbose_eval = 500\n",
    "train_data = lgb.Dataset(df_tr[x_col].values.astype(np.float32), label=(df_tr[f\"label_{hl}_20\"] - a_macro*df_tr[f\"macro_{hl}_ch_20\"] - a_sec*df_tr[f\"33sec_{hl}_ch_20\"]).values.astype(np.float32))\n",
    "eval_data = lgb.Dataset(df_vl[x_col].values.astype(np.float32), label=(df_vl[f\"label_{hl}_20\"] - a_macro*df_vl[f\"macro_{hl}_ch_20\"] - a_sec*df_vl[f\"33sec_{hl}_ch_20\"]).values.astype(np.float32), reference= train_data)\n",
    "\n",
    "model = lgb.train(params,train_data,valid_sets=eval_data, num_boost_round=num_boost_round, verbose_eval=verbose_eval, feval=eval_spearman)\n",
    "\n",
    "#安値予測モデルのエクスポート\n",
    "modelname = f'model_jpx_{hl}.pkl'\n",
    "\n",
    "with open(modelname, 'wb') as f:\n",
    "    pickle.dump(model,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
